{"cells":[{"cell_type":"markdown","metadata":{"id":"ZJk_OOude0EN"},"source":["# 코랩 환경설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvKkDhKUif5n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692866085630,"user_tz":-540,"elapsed":20814,"user":{"displayName":"정은","userId":"08814987957359372349"}},"outputId":"c1a746f4-61a7-4f81-d9a6-738adfa91dc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIMeGCCsqOor"},"outputs":[],"source":["# 현재 노트북 파일의 경로로 작업 디렉토리 변경\n","import os\n","notebook_path = '/content/drive/MyDrive/project'\n","os.chdir(notebook_path)"]},{"cell_type":"markdown","metadata":{"id":"WUkSkmocahfj"},"source":["# Mecab Download (For Colab)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pnej8x3Uapyy"},"outputs":[],"source":["!bash install_mecab-ko_on_colab_light_220429.sh # 1~3분정도 소요"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"suEwbc_-4mfw"},"outputs":[],"source":["from konlpy.tag import Mecab\n","# 안되면 위에 **디렉토리변경** 한 다음에 하세요~!!!!!!!!!!!!!!\n","tokenizer = Mecab(dicpath='mecab-ko-dic-2.1.1-20180720').nouns"]},{"cell_type":"markdown","metadata":{"id":"MjmegOylmDy9"},"source":["# 0. Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fhYLbNNBLMvK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692868724327,"user_tz":-540,"elapsed":657,"user":{"displayName":"정은","userId":"08814987957359372349"}},"outputId":"da67da4f-631c-4d29-d3dc-7017d766c641"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import sys\n","import csv\n","csv.field_size_limit(sys.maxsize)\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from sklearn import metrics\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","from torch.utils.data.dataset import Dataset\n","import numpy as np\n","import nltk # default word/sentence tokenizer\n","nltk.download('punkt')\n","from torch.utils.data import DataLoader\n","import shutil\n","# from konlpy.tag import Mecab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T47SongXmG8l"},"outputs":[],"source":["def get_evaluation(y_true, y_prob, list_metrics):\n","    y_pred = np.argmax(y_prob, -1)\n","    output = {}\n","    if 'accuracy' in list_metrics:\n","        output['accuracy'] = metrics.accuracy_score(y_true, y_pred)\n","    if 'loss' in list_metrics:\n","        try:\n","            output['loss'] = metrics.log_loss(y_true, y_prob)\n","        except ValueError:\n","            output['loss'] = -1\n","    if 'confusion_matrix' in list_metrics:\n","        output['confusion_matrix'] = str(metrics.confusion_matrix(y_true, y_pred))\n","    return output\n","\n","def matrix_mul(input, weight, bias=False):\n","    feature_list = []\n","    for feature in input:\n","        feature = torch.mm(feature, weight)\n","        if isinstance(bias, torch.nn.parameter.Parameter):\n","            feature = feature + bias.expand(feature.size()[0], bias.size()[1])\n","        feature = torch.tanh(feature).unsqueeze(0)\n","        feature_list.append(feature)\n","\n","    return torch.cat(feature_list, 0).squeeze()\n","\n","def element_wise_mul(input1, input2):\n","\n","    feature_list = []\n","    for feature_1, feature_2 in zip(input1, input2):\n","        feature_2 = feature_2.unsqueeze(1).expand_as(feature_1)\n","        feature = feature_1 * feature_2\n","        feature_list.append(feature.unsqueeze(0))\n","    output = torch.cat(feature_list, 0)\n","    return torch.sum(output, 0).unsqueeze(0)\n","\n","def get_max_lengths(data_path):\n","    word_length_list = []\n","    sent_length_list = []\n","    with open(data_path) as csv_file:\n","        reader = csv.reader(csv_file, quotechar='\"')\n","        for idx, line in enumerate(reader):\n","            text = \"\"\n","            for tx in line[1:]:\n","                text += tx.lower()\n","                text += \" \"\n","            sent_list = sent_tokenize(text)\n","            sent_length_list.append(len(sent_list))\n","\n","            for sent in sent_list:\n","                word_list = word_tokenize(sent)\n","                word_length_list.append(len(word_list))\n","\n","        sorted_word_length = sorted(word_length_list)\n","        sorted_sent_length = sorted(sent_length_list)\n","\n","    return sorted_word_length[int(0.9*len(sorted_word_length))], sorted_sent_length[int(0.9*len(sorted_sent_length))]"]},{"cell_type":"markdown","metadata":{"id":"X3j9UAungEhl"},"source":["# 1. Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vLxP6z5AgMW5"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, data_path, dict_path, max_length_sentences, max_length_word, tokenizer=word_tokenize):\n","        super(MyDataset, self).__init__()\n","\n","        texts, labels = [], []\n","        with open(data_path, encoding='utf-8-sig') as csv_file:\n","            reader = csv.reader(csv_file, quotechar='\"')\n","            for idx, line in enumerate(reader):\n","                text = \"\"\n","                for tx in line[1:]:\n","                    text += tx.lower()\n","                    text += \" \"\n","                label = int(line[0])\n","                texts.append(text)\n","                labels.append(label)\n","\n","        self.texts = texts\n","        self.labels = labels\n","        self.dict = pd.read_csv(filepath_or_buffer=dict_path, header=None, sep=\" \", quoting=csv.QUOTE_NONE,\n","                                usecols=[0]).values\n","        self.dict = [word[0] for word in self.dict]\n","        self.max_length_sentences = max_length_sentences\n","        self.max_length_word = max_length_word\n","        self.num_classes = len(set(self.labels)) # classification class num\n","\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        label = self.labels[index]\n","        text = self.texts[index]\n","        document_encode = [\n","            [self.dict.index(word) if word in self.dict else -1 for word in self.tokenizer(sentences)] for sentences\n","            in\n","            sent_tokenize(text=text)] # get dictionary's index\n","\n","        for sentences in document_encode: # padding (to max length word)\n","            if len(sentences) < self.max_length_word:\n","                extended_words = [-1 for _ in range(self.max_length_word - len(sentences))]\n","                sentences.extend(extended_words)\n","\n","        if len(document_encode) < self.max_length_sentences:\n","            extended_sentences = [[-1 for _ in range(self.max_length_word)] for _ in\n","                                  range(self.max_length_sentences - len(document_encode))]\n","            document_encode.extend(extended_sentences)\n","\n","        document_encode = [sentences[:self.max_length_word] for sentences in document_encode][\n","                          :self.max_length_sentences]\n","\n","        document_encode = np.stack(arrays=document_encode, axis=0) # 여러개의 배열을 하나의 배열로 쌓아올림\n","        document_encode += 1 # -1을 0으로 맞추기\n","\n","        return document_encode.astype(np.int64), label"]},{"cell_type":"markdown","metadata":{"id":"4CR5tDjAgIG1"},"source":["# 2. Word Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmPQxrdzk4kN"},"outputs":[],"source":["class WordAttNet(nn.Module):\n","    def __init__(self, dictionary_path, hidden_size=50):\n","        super(WordAttNet, self).__init__()\n","        dict = pd.read_csv(filepath_or_buffer=dictionary_path, header=None, sep=\" \",\n","                           quoting=csv.QUOTE_NONE).values[:,1:] # 두번째 열부터 선택\n","        dict_len, embed_size = dict.shape\n","        dict_len += 1\n","\n","        unknown_word = np.zeros((1, embed_size))\n","        # unknown_word 배열과 dict 배열을 합친 후, pytorch tensor로 변환함\n","        dict = torch.from_numpy(np.concatenate([unknown_word, dict], axis=0).astype(float))\n","\n","        self.word_weight = nn.Parameter(torch.Tensor(2 * hidden_size, 2 * hidden_size))\n","        self.word_bias = nn.Parameter(torch.Tensor(1, 2 * hidden_size))\n","        self.context_weight = nn.Parameter(torch.Tensor(2 * hidden_size, 1))\n","\n","        self.lookup = nn.Embedding(num_embeddings=dict_len, embedding_dim=embed_size).from_pretrained(dict)\n","\n","\n","        self.gru = nn.GRU(embed_size, hidden_size, bidirectional=True)\n","        self._create_weights(mean=0.0, std=0.05)\n","\n","    def _create_weights(self, mean=0.0, std=0.05):\n","\n","        self.word_weight.data.normal_(mean, std)\n","        self.context_weight.data.normal_(mean, std)\n","\n","    def forward(self, input, hidden_state):\n","\n","        output = self.lookup(input)\n","        f_output, h_output = self.gru(output.float(), hidden_state)  # feature output and hidden state output\n","        output = matrix_mul(f_output, self.word_weight, self.word_bias)\n","        output = matrix_mul(output, self.context_weight).permute(1,0)\n","        output = F.softmax(output, dim=1)\n","        output = element_wise_mul(f_output,output.permute(1,0))\n","\n","        return output, h_output"]},{"cell_type":"markdown","metadata":{"id":"l98t_4xzgJ3E"},"source":["# 3. Sentence Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsZtz3h2k-jN"},"outputs":[],"source":["class SentAttNet(nn.Module):\n","    def __init__(self, sent_hidden_size=50, word_hidden_size=50, num_classes=8):\n","        super(SentAttNet, self).__init__()\n","\n","        self.sent_weight = nn.Parameter(torch.Tensor(2 * sent_hidden_size, 2 * sent_hidden_size))\n","        self.sent_bias = nn.Parameter(torch.Tensor(1, 2 * sent_hidden_size))\n","        self.context_weight = nn.Parameter(torch.Tensor(2 * sent_hidden_size, 1))\n","\n","        self.gru = nn.GRU(2 * word_hidden_size, sent_hidden_size, bidirectional=True)\n","        self.fc = nn.Linear(2 * sent_hidden_size, num_classes)\n","\n","        self.sent_softmax = nn.Softmax(dim=1)\n","        self.fc_softmax = nn.Softmax(dim=1)\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(2 * sent_hidden_size, 32),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(32, num_classes)\n","        )\n","\n","        self._create_weights(mean=0.0, std=0.05)\n","\n","    def _create_weights(self, mean=0.0, std=0.05):\n","        self.sent_weight.data.normal_(mean, std)\n","        self.context_weight.data.normal_(mean, std)\n","\n","    def forward(self, input, hidden_state):\n","\n","        f_output, h_output = self.gru(input, hidden_state)\n","        output = matrix_mul(f_output, self.sent_weight, self.sent_bias)\n","        output = matrix_mul(output, self.context_weight).permute(1, 0)\n","        output = F.softmax(output, dim=1)\n","        output = element_wise_mul(f_output, output.permute(1, 0)).squeeze(0)\n","        output = self.classifier(output) ####\n","\n","        return output, h_output"]},{"cell_type":"markdown","metadata":{"id":"PgHPnwamlKod"},"source":["# 4. Hierarchical Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_btT6kilOwH"},"outputs":[],"source":["class HierAttNet(nn.Module):\n","    def __init__(self, word_hidden_size, sent_hidden_size, batch_size, num_classes, pretrained_dictionary_path,\n","                 max_sent_length, max_word_length):\n","        super(HierAttNet, self).__init__()\n","        self.batch_size = batch_size\n","        self.word_hidden_size = word_hidden_size\n","        self.sent_hidden_size = sent_hidden_size\n","        self.max_sent_length = max_sent_length\n","        self.max_word_length = max_word_length\n","        self.word_att_net = WordAttNet(pretrained_dictionary_path, word_hidden_size)\n","        self.sent_att_net = SentAttNet(sent_hidden_size, word_hidden_size, num_classes)\n","        self._init_hidden_state()\n","\n","    def _init_hidden_state(self, last_batch_size=None):\n","        if last_batch_size:\n","            batch_size = last_batch_size\n","        else:\n","            batch_size = self.batch_size\n","        self.word_hidden_state = torch.zeros(2, batch_size, self.word_hidden_size)\n","        self.sent_hidden_state = torch.zeros(2, batch_size, self.sent_hidden_size)\n","        if torch.cuda.is_available():\n","            self.word_hidden_state = self.word_hidden_state.cuda()\n","            self.sent_hidden_state = self.sent_hidden_state.cuda()\n","\n","    def forward(self, input):\n","\n","        output_list = []\n","        input = input.permute(1, 0, 2)\n","        for i in input:\n","            output, self.word_hidden_state = self.word_att_net(i.permute(1, 0), self.word_hidden_state)\n","            output_list.append(output)\n","        output = torch.cat(output_list, 0)\n","        output, self.sent_hidden_state = self.sent_att_net(output, self.sent_hidden_state)\n","\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"696CloJPh5aZ"},"source":["# parameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njK1dk4qh5aZ"},"outputs":[],"source":["batch_size = 32\n","num_epochs = 10\n","learning_rate = 1e-3\n","####################################################################################\n","word_hidden_size = 64\n","sent_hidden_size = 64\n","####################################################################################\n","# train_data = 'data/Training_dataset.txt' # training data\n","train_data = 'data/new_training_0823.txt'\n","test_data = 'data/new_validation_0823.txt'\n","####################################################################################\n","from konlpy.tag import Mecab\n","tokenizer = Mecab().nouns\n","dictionary_path = 'data/ko_w2v_version2.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2vDnHSSh5aa"},"outputs":[],"source":["training_params = {\"batch_size\": batch_size, \"shuffle\": True, \"drop_last\": True}\n","test_params = {'batch_size': batch_size, 'shuffle':False, \"drop_last\":False}\n","max_word_length, max_sent_length = 32, 20 #get_max_lengths(train_data) # 32 20 정도 하면 될듯 ..??\n","training_set = MyDataset(train_data, dictionary_path, max_sent_length, max_word_length, tokenizer=tokenizer)\n","training_generator = DataLoader(training_set, **training_params)\n","test_set = MyDataset(test_data, dictionary_path, max_sent_length, max_word_length, tokenizer=tokenizer)\n","test_generator = DataLoader(test_set, **test_params)"]},{"cell_type":"code","source":["max_word_length, max_sent_length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHlp3SsMZ320","executionInfo":{"status":"ok","timestamp":1692754880931,"user_tz":-540,"elapsed":8,"user":{"displayName":"정은","userId":"08814987957359372349"}},"outputId":"554f75e3-1faf-4cfc-bf01-7c523f87e7a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 20)"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"FWprX0LLm_Bq"},"source":["# model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymRxYc6Pe0EW"},"outputs":[],"source":["model = HierAttNet(\n","    word_hidden_size, sent_hidden_size,\n","    32, 2,\n","    dictionary_path, 20, 32\n","    )\n","\n","# move model to GPU\n","if torch.cuda.is_available():\n","    model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxwrtluT-zSx"},"outputs":[],"source":["from tqdm import tqdm, tqdm_notebook"]},{"cell_type":"markdown","metadata":{"id":"AZynKqNOe0EY"},"source":["### Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4nNBx9Jh5ad"},"outputs":[],"source":["# 손실함수와 optimizer를 정의합니다.\n","criterion = nn.CrossEntropyLoss()\n","# criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","best_loss = 1e5\n","best_epoch = 0\n","num_iter_per_epoch = len(training_generator)"]},{"cell_type":"markdown","metadata":{"id":"B4o-DeWh6vdI"},"source":["# 저장된 checkpoint 불러와서 다시 학습"]},{"cell_type":"code","source":["from torch.utils.tensorboard import SummaryWriter\n","logdir = 'logs'\n","writer = SummaryWriter(logdir)"],"metadata":{"id":"2sMzNQJQqubl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" 모델 epoch 평가 \"\"\"\n","def eval_epoch(num_epoch, epoch, model, criterion, optimizer, data_loader):\n","    model.eval() # 모델을 평가 모드로 설정\n","\n","    loss_ls = []\n","    te_label_ls = []\n","    te_pred_ls = []\n","\n","    with tqdm_notebook(total=len(data_loader), desc=f\"Valid\") as pbar:\n","        for feature, label in data_loader:\n","            num_sample = len(label)\n","\n","            if torch.cuda.is_available():\n","                feature = feature.cuda()\n","                label = label.cuda()\n","\n","            with torch.no_grad():\n","                model._init_hidden_state(num_sample)\n","                te_predictions = model(feature)\n","\n","            te_loss = criterion(te_predictions, label)\n","            loss_ls.append(te_loss * num_sample)\n","            te_label_ls.extend(label.clone().cpu())\n","            te_pred_ls.append(te_predictions.clone().cpu())\n","            pbar.update(1)\n","\n","        te_loss = sum(loss_ls) / test_set.__len__()\n","        te_pred = torch.cat(te_pred_ls, 0)\n","        label = np.array(te_label_ls)\n","        test_metrics = get_evaluation(label, te_pred.numpy(), list_metrics=[\"accuracy\", \"confusion_matrix\"])\n","        confusion_matrix_str = test_metrics.get('confusion_matrix', None)\n","\n","        print(\"Epoch: {}/{}, Lr: {}, Loss: {}, Accuracy: {}\".format(\n","            epoch + 1,\n","            num_epochs,\n","            optimizer.param_groups[0]['lr'],\n","            te_loss, test_metrics[\"accuracy\"]))\n","\n","    return test_metrics[\"accuracy\"], test_metrics[\"confusion_matrix\"]"],"metadata":{"id":"52kn36gOj3r3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_losses = []"],"metadata":{"id":"WzkstjCPPLmg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = HierAttNet(word_hidden_size, sent_hidden_size, 32, 2, dictionary_path, 20, 32)"],"metadata":{"id":"_Ukc1ycnDUOs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_hidden_size, sent_hidden_size, dictionary_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BPEipFD4DXJl","executionInfo":{"status":"ok","timestamp":1692872463214,"user_tz":-540,"elapsed":401,"user":{"displayName":"정은","userId":"08814987957359372349"}},"outputId":"d1ba6857-bf99-4e14-8c1b-6e92c0803a50"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64, 64, 'data/ko_w2v_version2.txt')"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dhnV1PXgc9I","executionInfo":{"status":"ok","timestamp":1692879935849,"user_tz":-540,"elapsed":365,"user":{"displayName":"정은","userId":"08814987957359372349"}},"outputId":"75410648-45eb-4750-f338-1767b088f8db"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/                               Model_Saved_dict.pth\n","Classify_HAN.ipynb                         Model_Saved.pth\n","\u001b[01;34mdata\u001b[0m/                                      models.py\n","install_mecab-ko_on_colab_light_220429.sh  \u001b[01;34m__pycache__\u001b[0m/\n","ko_w2v_128.txt                             Training_0823_WED_sub.ipynb\n","\u001b[01;34mlogs\u001b[0m/                                      Untitled0.ipynb\n","\u001b[01;34mmecab-ko-dic-2.1.1-20180720\u001b[0m/\n"]}]},{"cell_type":"code","source":["checkpoint_path = 'checkpoints/N_model_epoch_5_0.83.pth'  # 원하는 체크포인트 파일 경로\n","checkpoint = torch.load(checkpoint_path)\n","model.load_state_dict(checkpoint['model_state_dict'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZrEk01nDRPE","executionInfo":{"status":"ok","timestamp":1692872378183,"user_tz":-540,"elapsed":393,"user":{"displayName":"정은","userId":"08814987957359372349"}},"outputId":"2a9dd4f7-8e97-496f-f19f-f46c127bb80f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RL56YyhVrsjf","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["10d72618e6e24bc6a2114942f5db0d47","5316e6f18df14443b16de6bb3bea831e","33e199a7acc448feb5e139e2cc7e3668","4baa6915a64448998bb6fc47883a8a01","10e35739a6874bfbb7dd81cd748f17ca","f456dc69194746d5955fbc1159482aa6","0f6538bad51b4f83930d1edbefba06fa","f8d224bc721443a7aa203ef43713b12a","87ea72086f214e4c99378f34a86b2a0f","e58b8af2ad78441bb4b164695f975294","82402216e85846fca5606c671fba5a51","9f00622e312a4e2ab65d41bff1f4ff62","075516bb9acb4654a7aea4f41e6206be","dab5d49158c04e04adfec754d21946dd","82d453928f3947e69fb96d7ca05da865","463f7ebafee54b3aa1713dbb3c021af5","3a76def376764264918b89d7fac73ac0","7daa75264c2b4a2e8005e606f6207f65","901bc7b4fd6e457fa71641487f129121","ff8973df063145d993919b9a732de2cb","79b1be8315364258ad24857036a37464","951b91643a14450791ea22795e7f108d","fbc73480ce934ff6803cee40ca9a9adc","2f112768250f4750840d5143d9ec5470","759c945b6b934f1b9d568cd6a39d6dbb","fedec8c21a944d70983868cc39ca2395","eb02449809c44e3597dbd3ef2efb23f3","8fa93a0e459340bc994dfe43696e93c4","537abe0e3c934a03bc39b6e106980c7b","24829a58e5d74e719dbf557d71a72dbc","9bf2983a1cda4cc384267b7466e7afa7","9845067c0bb745f6b1cd8febac4cb34f","c40ad192e3844b919090d5b3fde093fc"]},"outputId":"4fea0f9c-8005-4f27-c6c4-1610c20111f2","executionInfo":{"status":"error","timestamp":1692793909420,"user_tz":-540,"elapsed":2068966,"user":{"displayName":"정은","userId":"08814987957359372349"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 6/10, Iteration: 100/1195, Lr: 0.001, Loss: 0.2434108555316925, Accuracy: 0.875\n","Epoch: 6/10, Iteration: 200/1195, Lr: 0.001, Loss: 0.19735310971736908, Accuracy: 0.9375\n","Epoch: 6/10, Iteration: 300/1195, Lr: 0.001, Loss: 0.2981373369693756, Accuracy: 0.9375\n","Epoch: 6/10, Iteration: 400/1195, Lr: 0.001, Loss: 0.22876238822937012, Accuracy: 0.9375\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-17-cd8aad4ce4d3>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  with tqdm_notebook(total=len(data_loader), desc=f\"Valid\") as pbar:\n"]},{"output_type":"display_data","data":{"text/plain":["Valid:   0%|          | 0/71 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10d72618e6e24bc6a2114942f5db0d47"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 6/10, Lr: 0.001, Loss: 0.41569772362709045, Accuracy: 0.8142222222222222\n","[[929 247]\n"," [171 903]]\n","Epoch: 6/10, Iteration: 500/1195, Lr: 0.001, Loss: 0.24215760827064514, Accuracy: 0.90625\n","Epoch: 6/10, Iteration: 600/1195, Lr: 0.001, Loss: 0.326753169298172, Accuracy: 0.84375\n","Epoch: 6/10, Iteration: 700/1195, Lr: 0.001, Loss: 0.1374119371175766, Accuracy: 0.96875\n","Epoch: 6/10, Iteration: 800/1195, Lr: 0.001, Loss: 0.4024469554424286, Accuracy: 0.875\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-17-cd8aad4ce4d3>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  with tqdm_notebook(total=len(data_loader), desc=f\"Valid\") as pbar:\n"]},{"output_type":"display_data","data":{"text/plain":["Valid:   0%|          | 0/71 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f00622e312a4e2ab65d41bff1f4ff62"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 6/10, Lr: 0.001, Loss: 0.4005464017391205, Accuracy: 0.832\n","[[893 283]\n"," [ 95 979]]\n","Epoch: 6/10, Iteration: 900/1195, Lr: 0.001, Loss: 0.24977155029773712, Accuracy: 0.9375\n","Epoch: 6/10, Iteration: 1000/1195, Lr: 0.001, Loss: 0.2938868999481201, Accuracy: 0.875\n","Epoch: 6/10, Iteration: 1100/1195, Lr: 0.001, Loss: 0.18118931353092194, Accuracy: 0.9375\n","Epoch: 7/10, Iteration: 100/1195, Lr: 0.001, Loss: 0.09860434383153915, Accuracy: 1.0\n","Epoch: 7/10, Iteration: 200/1195, Lr: 0.001, Loss: 0.13084714114665985, Accuracy: 0.9375\n","Epoch: 7/10, Iteration: 300/1195, Lr: 0.001, Loss: 0.22303692996501923, Accuracy: 0.96875\n","Epoch: 7/10, Iteration: 400/1195, Lr: 0.001, Loss: 0.22302667796611786, Accuracy: 0.875\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-17-cd8aad4ce4d3>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  with tqdm_notebook(total=len(data_loader), desc=f\"Valid\") as pbar:\n"]},{"output_type":"display_data","data":{"text/plain":["Valid:   0%|          | 0/71 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbc73480ce934ff6803cee40ca9a9adc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 7/10, Lr: 0.001, Loss: 0.46935051679611206, Accuracy: 0.8217777777777778\n","[[923 253]\n"," [148 926]]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-e50fe5a9d35e>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnum_iter_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 모델을 학습 모드로 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-502d62078168>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         document_encode = [\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-502d62078168>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         document_encode = [\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             sent_tokenize(text=text)] # get dictionary's index\n","\u001b[0;32m<ipython-input-7-502d62078168>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         document_encode = [\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             sent_tokenize(text=text)] # get dictionary's index\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model_path = 'checkpoints/'\n","model_name_template = 'N_model_epoch_{}_{}.pth'\n","num_iter_per_epoch = len(training_generator)\n","\n","checkpoint_path = 'checkpoints/N_model_epoch_4_0.81.pth'  # 원하는 체크포인트 파일 경로\n","\n","checkpoint = torch.load(checkpoint_path)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","start_epoch = checkpoint['epoch'] + 1  # 재개할 에포크 설정\n","\n","\n","# 학습 재개\n","\n","PATH = f'{model_path}/Model_save0.pth'\n","torch.save(model, PATH)\n","\n","\n","for epoch in range(start_epoch, num_epochs):\n","    params = {'num_epoch': num_epochs, 'epoch': epoch, 'model': model, 'optimizer': optimizer, 'criterion': criterion}\n","\n","\n","    num_iter_per_epoch = len(training_generator)\n","\n","    for iter, (feature, label) in enumerate(training_generator):\n","        model.train() # 모델을 학습 모드로 설정\n","        if torch.cuda.is_available():\n","            feature = feature.cuda()\n","            label = label.cuda()\n","\n","        model._init_hidden_state()\n","        predictions = model(feature)\n","\n","        # 손실 함수를 이용하여 loss를 계산\n","        loss = criterion(predictions, label)\n","\n","        # optimizer의 gradient 초기화\n","        optimizer.zero_grad()\n","        loss.backward() # gradient 계산\n","        optimizer.step() # model's parameter update using optimizer\n","\n","        training_metrics = get_evaluation(label.cpu().numpy(), predictions.cpu().detach().numpy(), list_metrics=[\"accuracy\"])\n","\n","        if (iter+1) % 100 == 0:\n","          print(\"Epoch: {}/{}, Iteration: {}/{}, Lr: {}, Loss: {}, Accuracy: {}\".format(\n","              epoch + 1,\n","              num_epochs,\n","              iter + 1,\n","              num_iter_per_epoch,\n","              optimizer.param_groups[0]['lr'],\n","              loss, training_metrics[\"accuracy\"]))\n","\n","        # 100번째 반복마다 저장 및 validation\n","        if (iter+1) % 400 == 0:\n","            # 모델 및 옵티마이저 상태 저장\n","            accuracy, confusion_matrix = eval_epoch(**params, data_loader=test_generator)\n","            print(confusion_matrix)\n","            model_file_name = model_name_template.format(epoch, round(accuracy,2))\n","            torch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'epoch': epoch}, model_path + model_file_name)\n","            PATH = f'{model_path}/Model_save_{epoch}'\n","            torch.save(model, PATH)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"vscode":{"interpreter":{"hash":"f41e1cc7670ea4f36b583d0300139665460618ecf0268b6e88e349fe439dc38f"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"10d72618e6e24bc6a2114942f5db0d47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5316e6f18df14443b16de6bb3bea831e","IPY_MODEL_33e199a7acc448feb5e139e2cc7e3668","IPY_MODEL_4baa6915a64448998bb6fc47883a8a01"],"layout":"IPY_MODEL_10e35739a6874bfbb7dd81cd748f17ca"}},"5316e6f18df14443b16de6bb3bea831e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f456dc69194746d5955fbc1159482aa6","placeholder":"​","style":"IPY_MODEL_0f6538bad51b4f83930d1edbefba06fa","value":"Valid: 100%"}},"33e199a7acc448feb5e139e2cc7e3668":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8d224bc721443a7aa203ef43713b12a","max":71,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87ea72086f214e4c99378f34a86b2a0f","value":71}},"4baa6915a64448998bb6fc47883a8a01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e58b8af2ad78441bb4b164695f975294","placeholder":"​","style":"IPY_MODEL_82402216e85846fca5606c671fba5a51","value":" 71/71 [00:56&lt;00:00,  1.56it/s]"}},"10e35739a6874bfbb7dd81cd748f17ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f456dc69194746d5955fbc1159482aa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f6538bad51b4f83930d1edbefba06fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8d224bc721443a7aa203ef43713b12a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87ea72086f214e4c99378f34a86b2a0f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e58b8af2ad78441bb4b164695f975294":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82402216e85846fca5606c671fba5a51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f00622e312a4e2ab65d41bff1f4ff62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_075516bb9acb4654a7aea4f41e6206be","IPY_MODEL_dab5d49158c04e04adfec754d21946dd","IPY_MODEL_82d453928f3947e69fb96d7ca05da865"],"layout":"IPY_MODEL_463f7ebafee54b3aa1713dbb3c021af5"}},"075516bb9acb4654a7aea4f41e6206be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a76def376764264918b89d7fac73ac0","placeholder":"​","style":"IPY_MODEL_7daa75264c2b4a2e8005e606f6207f65","value":"Valid: 100%"}},"dab5d49158c04e04adfec754d21946dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_901bc7b4fd6e457fa71641487f129121","max":71,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff8973df063145d993919b9a732de2cb","value":71}},"82d453928f3947e69fb96d7ca05da865":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79b1be8315364258ad24857036a37464","placeholder":"​","style":"IPY_MODEL_951b91643a14450791ea22795e7f108d","value":" 71/71 [00:54&lt;00:00,  1.75it/s]"}},"463f7ebafee54b3aa1713dbb3c021af5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a76def376764264918b89d7fac73ac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7daa75264c2b4a2e8005e606f6207f65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"901bc7b4fd6e457fa71641487f129121":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff8973df063145d993919b9a732de2cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79b1be8315364258ad24857036a37464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"951b91643a14450791ea22795e7f108d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbc73480ce934ff6803cee40ca9a9adc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f112768250f4750840d5143d9ec5470","IPY_MODEL_759c945b6b934f1b9d568cd6a39d6dbb","IPY_MODEL_fedec8c21a944d70983868cc39ca2395"],"layout":"IPY_MODEL_eb02449809c44e3597dbd3ef2efb23f3"}},"2f112768250f4750840d5143d9ec5470":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fa93a0e459340bc994dfe43696e93c4","placeholder":"​","style":"IPY_MODEL_537abe0e3c934a03bc39b6e106980c7b","value":"Valid: 100%"}},"759c945b6b934f1b9d568cd6a39d6dbb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24829a58e5d74e719dbf557d71a72dbc","max":71,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bf2983a1cda4cc384267b7466e7afa7","value":71}},"fedec8c21a944d70983868cc39ca2395":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9845067c0bb745f6b1cd8febac4cb34f","placeholder":"​","style":"IPY_MODEL_c40ad192e3844b919090d5b3fde093fc","value":" 71/71 [00:55&lt;00:00,  1.41it/s]"}},"eb02449809c44e3597dbd3ef2efb23f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fa93a0e459340bc994dfe43696e93c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"537abe0e3c934a03bc39b6e106980c7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24829a58e5d74e719dbf557d71a72dbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bf2983a1cda4cc384267b7466e7afa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9845067c0bb745f6b1cd8febac4cb34f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c40ad192e3844b919090d5b3fde093fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
